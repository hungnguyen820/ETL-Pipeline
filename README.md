# ETL-Pipeline: Largest Banks Market Capitalization
This project is an end-to-end ETL (Extract, Transform, Load) pipeline that retrieves data from Wikipedia about the largest banks in the world by market capitalization, transforms the data using currency exchange rates, and loads it into both a CSV file and an SQLite database.

## ğŸ”§ Technologies Used

- Python 3
- pandas
- numpy
- requests
- BeautifulSoup (bs4)
- SQLite (via sqlite3)

## ğŸš€ Features

- Extracts a table from a static archived version of Wikipedia
- Cleans and parses market capitalization data
- Converts market cap values from USD to GBP, EUR, and INR using custom exchange rates
- Saves the transformed data to:
  - A local CSV file
  - A local SQLite database (`Banks.db`)
- Logs all steps and events to a log file (`code_log.txt`)
- Includes a sample SQL query to validate stored data

## ğŸ“¦ File Structure

â”œâ”€â”€ etl-largest-banks-market-cap.ipynb # Main Python script
â”œâ”€â”€ exchange_rate_data.ipynb # Create exchange_rate.csv
â”œâ”€â”€ exchange_rate.csv # Currency conversion rates
â”œâ”€â”€ transformed_data.csv # Output file with converted values
â”œâ”€â”€ Banks.db # SQLite database (created after first run)
â””â”€â”€ code_log.txt # Log file generated during execution


## ğŸ“ Prerequisites

Install required packages using pip:

```bash
pip install pandas numpy requests beautifulsoup4

## ğŸ“Œ Notes
The Wikipedia URL used is an archived version for consistency.

The exchange rate file is simplified for demonstration. In real-world scenarios, dynamic FX API integration is recommended.

## ğŸ‘¤ Author
Hung Nguyen

GitHub link: https://github.com/hungnguyen820

Email: hungnguyen29820@gmail.com

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89bd3f72-f589-4636-8dd7-b5008288ffbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe successfully saved to transformed_data.csv\n",
      "Data loaded into SQLite database.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import sqlite3\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Log each step of the ETL process to a text file\n",
    "def log_progress(message):\n",
    "    time_stamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    log_entry = f\"{time_stamp} : {message}\\n\"\n",
    "    with open('code_log.txt', 'a') as log_file:\n",
    "        log_file.write(log_entry)\n",
    "\n",
    "# Extract: Scrape a Wikipedia page and parse the target table using BeautifulSoup\n",
    "def extract(url, table_attribs):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    table = soup.find('table', attrs=table_attribs)\n",
    "    if table is None:\n",
    "        print(\"Target table with specified class not found.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Parse table headers\n",
    "    headers = [th.get_text(strip=True) for th in table.find_all('tr')[0].find_all('th')]\n",
    "\n",
    "    # Parse table rows\n",
    "    rows = []\n",
    "    for tr in table.find_all('tr')[1:]:\n",
    "        cols = tr.find_all(['td', 'th'])\n",
    "        row = [col.get_text(strip=True).replace(',', '') for col in cols]\n",
    "        if len(row) == len(headers):\n",
    "            rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "    # Rename and convert the 'Market cap' column\n",
    "    col_name = next((c for c in df.columns if 'Market cap' in c and 'US$' in c), None)\n",
    "    if col_name:\n",
    "        df = df.rename(columns={col_name: 'MC_USD_Billion'})\n",
    "        df['MC_USD_Billion'] = pd.to_numeric(df['MC_USD_Billion'], errors='coerce')\n",
    "    else:\n",
    "        print(\"Column 'Market cap (US$ billion)' not found.\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# Transform: Convert market cap values from USD to GBP, EUR, and INR using exchange rates\n",
    "def transform(df, csv_path):\n",
    "    exchange_rate_df = pd.read_csv(csv_path)\n",
    "    exchange_rate = exchange_rate_df.set_index('Currency').to_dict()['Rate']\n",
    "    df['MC_GBP_Billion'] = np.round(df['MC_USD_Billion'] * exchange_rate['GBP'], 2)\n",
    "    df['MC_EUR_Billion'] = np.round(df['MC_USD_Billion'] * exchange_rate['EUR'], 2)\n",
    "    df['MC_INR_Billion'] = np.round(df['MC_USD_Billion'] * exchange_rate['INR'], 2)\n",
    "    return df\n",
    "\n",
    "# Load: Export the transformed DataFrame to a CSV file\n",
    "def load_to_csv(df, output_path):\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Dataframe successfully saved to {output_path}\")\n",
    "    log_progress(f\"Dataframe saved to {output_path}\")\n",
    "\n",
    "# Load: Store the transformed DataFrame into an SQLite database\n",
    "def load_to_db(df, sql_connection, table_name):\n",
    "    try:\n",
    "        df.to_sql(table_name, sql_connection, if_exists='replace', index=False)\n",
    "        print(\"Data loaded into SQLite database.\")\n",
    "        log_progress(\"Data loaded into SQLite database.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        log_progress(f\"Error while loading into DB: {e}\")\n",
    "\n",
    "# Query: Execute a query against the SQLite database\n",
    "def run_query(query_statement, sql_connection):\n",
    "    try:\n",
    "        cursor = sql_connection.cursor()\n",
    "        cursor.execute(query_statement)\n",
    "        results = cursor.fetchall()\n",
    "        print(f\"Query: {query_statement}\")\n",
    "        for row in results:\n",
    "            print(row)\n",
    "        log_progress(f\"Executed query: {query_statement}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        log_progress(f\"Query failed: {e}\")\n",
    "\n",
    "# ===== MAIN ETL EXECUTION =====\n",
    "log_progress(\"ETL process started.\")\n",
    "\n",
    "url = \"https://web.archive.org/web/20230908091635/https://en.wikipedia.org/wiki/List_of_largest_banks\"\n",
    "table_attribs = {'class': 'wikitable'}\n",
    "df = extract(url, table_attribs)\n",
    "log_progress(\"Data extraction completed.\")\n",
    "\n",
    "csv_path = 'exchange_rate.csv'\n",
    "df_transformed = transform(df, csv_path)\n",
    "log_progress(\"Data transformation completed.\")\n",
    "\n",
    "output_path = 'transformed_data.csv'\n",
    "load_to_csv(df_transformed, output_path)\n",
    "\n",
    "connection = sqlite3.connect('Banks.db')\n",
    "load_to_db(df_transformed, connection, 'Largest_banks')\n",
    "\n",
    "# Run a Query test\n",
    "run_query(\"SELECT * FROM Largest_banks LIMIT 5;\", connection)\n",
    "connection.close()\n",
    "\n",
    "log_progress(\"ETL process completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97341e84-4525-41a0-8f49-cbbc6536aa23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
